{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of songs and their lyrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and loading of libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import unidecode\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and sources\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data about songs\n",
    "Between 1848 and ca. 1914 typographical associations created booklets with lyrics of songs they sang during feasts they organized. The dataset contains a table (in CSV) with an overview of all the songs in the booklets between 1848 and 1870, with among others title, year and writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs:    771\n",
      "Number of booklets:  64\n"
     ]
    }
   ],
   "source": [
    "liedjesDF = pd.read_csv(\"../data/liedjes.csv\", dtype={'jaartal': 'Int32'})\n",
    "liedjesDF = liedjesDF.sort_values(by=['songID'])\n",
    "\n",
    "print(\"Number of songs:    \" + str(len(liedjesDF)))\n",
    "print(\"Number of booklets:  \" + str(len(liedjesDF['sourceID'].unique())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song lyrics from files\n",
    "Besides the overview of the songs in a CSV-file, for every song there is a machine readable representation of the lyrics. We use the following functions to process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlistOfFilenames(rootdir):\n",
    "    # input: rootdir: directory with (subdirectory with) TXT-files to be handled\n",
    "\t# output: list of TXT-files(+path) lexicographically ordered on path-name\n",
    "\n",
    "    files_all = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            if not file.endswith('.txt'):\n",
    "                continue\n",
    "            fn = os.path.join(subdir, file)\n",
    "            files_all.append(fn)\n",
    "\n",
    "    files_all = sorted(files_all)\n",
    "    return files_all\n",
    "\n",
    "def getlistOfTexts(listOfFilenames):\n",
    "\t# input: listOfFilenames: list of TXT-files(+path) lexicographically ordered on path-name\n",
    "    # output: list of texts\n",
    "\n",
    "\ttexts = []\n",
    "\tfor file in listOfFilenames:\n",
    "\t\twith open(file) as stream:\n",
    "\t\t\ttext = stream.read()\n",
    "\t\ttexts.append(text)\n",
    "\n",
    "\treturn texts\n",
    "\n",
    "def lemmatize(listOfTexts, select = True, allowed_postags=[\"NOUN\", \"ADJ\", \"ADV\", \"VERB\"]):   \n",
    "    # input: listOfTexts: list of Dutch texts\n",
    "    # input: allowed_postags: list of wordtypes to be kept in the lemmatization process\n",
    "    # output: list of lemmatized Dutch texts (list of lists of words). Lemmatization by spaCy.\n",
    "\n",
    "    nlp = spacy.load(\"nl_core_news_sm\") # create spaCy processor named 'nlp' based on small model for Dutch\n",
    "\n",
    "    result = []                                                         \n",
    "    for text in listOfTexts:                                                     \n",
    "\n",
    "        nlp.max_length = len(text)  \n",
    "        doc = nlp(text) # tokenize, lemmatize and annotate 'text' with processor named 'nlp'\n",
    "\n",
    "        new_text = []\n",
    "        for token in doc: \n",
    "            if token.is_alpha: # keep tokens with alphanumerical characters (so no numbers or punctuation)\n",
    "                if not token.is_stop: # remove stopwords\n",
    "                    if select:\n",
    "                            if token.pos_ in allowed_postags: # keep wordtypes in the allowed_postags list\n",
    "                                new_text.append(unidecode.unidecode(token.lemma_)) # get the word in the lemma and add it to the list of words\n",
    "                    else: new_text.append(unidecode.unidecode(token.lemma_))\n",
    "\n",
    "        result.append(\" \".join(new_text)) # add text to the list of lemmatized texts\n",
    "\n",
    "    return result\n",
    "    \n",
    "def replace(listOfWords, replaceWords):\n",
    "    # input: listOfWords: list \n",
    "    i = 0\n",
    "    for word in listOfWords:\n",
    "        if word in replaceWords:\n",
    "            listOfWords[i] = replaceWords[word]\n",
    "        i = i + 1\n",
    "\n",
    "    return listOfWords\n",
    "\n",
    "def remove(listOfWords, removeWords):\n",
    "    i = 0\n",
    "    for word in listOfWords:\n",
    "        if word in removeWords:\n",
    "            listOfWords.pop(i)\n",
    "        i = i + 1\n",
    "\n",
    "    return listOfWords\n",
    "\n",
    "def preprocess(listOfTexts, replaceDict, removeList):\n",
    "    result = []\n",
    "    for liedje in listOfTexts:\n",
    "        liedje = liedje.lower().split()\n",
    "        preprocessedLiedje = remove(replace(liedje, replaceDict), removeList)\n",
    "        result.append(\" \".join(preprocessedLiedje))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the above functions to read the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "liedjesFilenames    = getlistOfFilenames('../data/lyrics')\n",
    "liedjes             = getlistOfTexts(liedjesFilenames)\n",
    "lemmatizedLiedjes   = lemmatize(liedjes, select = False)\n",
    "\n",
    "replaceDict = {\"koster\":\"coster\", \"kosters\":\"costers\", \"vreugd\":\"vreugde\", \"blijd\":\"blijde\"}\n",
    "removeList  = [\"ha\", \"deez\", \"zoo\", \"hoezee\", \"tra\", \"la\", \"li\", \"eene\", \"weer\", \"uw\", \n",
    "                \"waarmee\", \"immer\", \"t\", \"d\", \"wijze\", \"hurah\", \"o\"]\n",
    "\n",
    "preprocessedLiedjes = preprocess(lemmatizedLiedjes, replaceDict, removeList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To investigate whether our code has worked, we look at the data of song with number ```n```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- data: --\n",
      "typoID                                      amsterdam1857-1\n",
      "sourceID                   amsterdam1857-1-feestbundel1862b\n",
      "songID                  amsterdam1857-1-feestbundel1862b-06\n",
      "titel                                       Typographenlied\n",
      "wijze                    Eens werd er aan de zeeuwsche kust\n",
      "jaartal                                                1862\n",
      "schrijver                                         I. Poster\n",
      "vereniging_schrijver                        amsterdam1857-1\n",
      "Name: 264, dtype: object\n",
      "-- path: --\n",
      "../data/lyrics/amsterdam1857-1/amsterdam1857-1-feestbundel1862b/amsterdam1857-1-feestbundel1862b-06.txt\n",
      "-- song: --\n",
      "Typographen-lied\n",
      "\n",
      "Eens zag men in de Spaarnestad\n",
      "Een groot genie verrijzen ;\n",
      "Dat 't nakroost hem ook niet vergat,\n",
      "Hiervan zijn de bewijzen.\n",
      "Hij spreidde op de aard het grootste licht ;\n",
      "Een standbeeld werd hem opgerigt.\n",
      "Zijn naam zal eeuwig leven,\n",
      "Zijn geest ons steeds omzweven.\n",
      "Geen Tromp, de Ruijter, zelfs hoe groot,\n",
      "Of welken held men noemt,\n",
      "Geen die zoo veel als Coster bood,\n",
      "Door zijne kunst beroemd.\n",
      "\n",
      "En nu is het al zesd’half jaar,\n",
      "Dat wij ons zaam vereenen,\n",
      "Verkondigen de blijde maar,\n",
      "Dat Coster is verschenen.\n",
      "Veel vrienden, met ons hier vereend,\n",
      "Zij zingen even welgemeend:\n",
      "Zijn kroost moog’ blijven leven,\n",
      "De voorspoed hen omgeven!\n",
      "Lang leve Nebrlands Drukpers-bond ,\n",
      "Zij stichte op aard veel nut,\n",
      "Dat ze eenmaal nog haar doeleind vond,\n",
      "Wenscht elk die haar thans stut.\n",
      "\n",
      "Wij, broeders onder een banier!\n",
      "Volijvrig zij ons s'reven.\n",
      "Thans tokklen wij verheugd de lier,\n",
      "Bij ’t schouwspel, ons gegeven ;\n",
      "Maar hooger moet ons doelwit zijn :\n",
      "De spruit, in d’ aanvang nog zoo klein,\n",
      "Kan tot een boom eens groeijen ,\n",
      "De drukpers moet meer bloeijen ,\n",
      "Dat slechts vooruitgang ’t streven zij,\n",
      "Vooruitgaan in het vak,\n",
      "Vooruitgang in de maatschappij ,\n",
      "Vooruitgaan in den zak.\n",
      "\n",
      "-- lemmatized song: --\n",
      "zien Spaarnestad groot genie verrijzen nakroost vergeten hiervan bewijs spreiden aard groot licht standbeeld opgerigen naam Eeuwig leven geest omzweven Tromp Ruijter groot held noemen zoo Coster bieden kunst beroemd zesd half jaar zaam vereenen Verkondigen blijde Coster verschijnen vriend vereen zingen welgemeend kroost moog blijven leven voorspoed omgeven leven Nebrlands stichte aard nut eenmaal doeleind vinden wenscht stut broeder banier volijvrig tokklen verheugd lier schouwspel hooger doelwit spruit d aanvang zoo klein boom groeij drukper bloeij vooruitgang streven vooruitgaan vak vooruitgang maatschappij vooruitgaan zak\n",
      "-- preprocessed song: --\n",
      "zien spaarnestad groot genie verrijzen nakroost vergeten hiervan bewijs spreiden aard groot licht standbeeld opgerigen naam eeuwig leven geest omzweven tromp ruijter groot held noemen coster bieden kunst beroemd zesd half jaar zaam vereenen verkondigen blijde coster verschijnen vriend vereen zingen welgemeend kroost moog blijven leven voorspoed omgeven leven nebrlands stichte aard nut eenmaal doeleind vinden wenscht stut broeder banier volijvrig tokklen verheugd lier schouwspel hooger doelwit spruit aanvang klein boom groeij drukper bloeij vooruitgang streven vooruitgaan vak vooruitgang maatschappij vooruitgaan zak\n"
     ]
    }
   ],
   "source": [
    "n = 200\n",
    "\n",
    "print(\"-- data: --\")\n",
    "print(liedjesDF.iloc[n])\n",
    "print(\"-- path: --\")\n",
    "print(liedjesFilenames[n])\n",
    "print(\"-- song: --\")\n",
    "print(liedjes[n])\n",
    "print(\"-- lemmatized song: --\")\n",
    "print(lemmatizedLiedjes[n])\n",
    "print(\"-- preprocessed song: --\")\n",
    "print(preprocessedLiedjes[n])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(listOfTexts):\n",
    "    # input: list of strings\n",
    "    # output: list of list of strings ('words')\n",
    "    result = []\n",
    "    for liedje in listOfTexts:\n",
    "        liedje = liedje.split()\n",
    "        result.append(liedje)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_vocabulary(tokenized_corpus):\n",
    "    # output: list of unique words derived from a list of lists of strings\n",
    "    vocabulary = []\n",
    "    for word_list in tokenized_corpus:\n",
    "        for word in word_list:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "\n",
    "    return sorted(vocabulary)\n",
    "\n",
    "\n",
    "def count_words(vocabulary, tokenized_corpus):\n",
    "\t# output: dictionary with word count per word from the vocabulary in the tokenized corpus.\n",
    "\n",
    "\t# init\n",
    "    count_dict = {}\n",
    "    for word in vocabulary:\n",
    "        count_dict[word] = 0\n",
    "\n",
    "\t# count\n",
    "    for text_list in tokenized_corpus:\n",
    "        for word in text_list:\n",
    "            count_dict[word] = count_dict[word] + 1\n",
    "\n",
    "    return count_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cut up all Liedjes into lists of separate strings ('words')\n",
    "listifiedLiedjes = listify(preprocessedLiedjes)\n",
    "\n",
    "# generate vocabulary\n",
    "liedjesVocabulary = extract_vocabulary(listifiedLiedjes)\n",
    "\n",
    "# create dict with number of occurances per word in the corpus\n",
    "count = count_words(liedjesVocabulary, listifiedLiedjes)\n",
    "\n",
    "# sort this dict descending\n",
    "sorted_count = dict(sorted(count.items(), key = lambda x: x[1], reverse = True))\n",
    "\n",
    "# check the number of occurances of the word 'coster' in the corpus\n",
    "count['coster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coster 867\n",
      "vreugde 669\n",
      "feest 604\n",
      "kunst 469\n",
      "zingen 467\n",
      "jaar 448\n",
      "eer 434\n",
      "vrolijk 419\n",
      "komt 409\n",
      "geest 408\n",
      "leven 376\n",
      "gaan 365\n",
      "blij 348\n",
      "hart 329\n",
      "zien 308\n",
      "laten 307\n",
      "lied 285\n",
      "dag 284\n",
      "drukkunst 280\n",
      "staan 276\n",
      "heil 269\n",
      "vieren 268\n",
      "kopperfeest 265\n",
      "vriendschap 257\n",
      "blijven 250\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key, value in sorted_count.items():\n",
    "    if i < 25:\n",
    "        print(key, value)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(document, word):\n",
    "    N = len(document)\n",
    "    occurance = len([token for token in document if token == word])\n",
    "\n",
    "    return occurance / N\n",
    "\n",
    "\n",
    "def inverse_document_frequency(tokenized_corpus, word, vocabulary):\n",
    "    word_count = count_words(vocabulary, tokenized_corpus)\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "\n",
    "    return np.log((len(tokenized_corpus) + 1) / word_occurance)\n",
    "\n",
    "\n",
    "def tf_idf(tokenized_corpus, document, word, vocabulary):\n",
    "    tf = term_frequency(document, word)\n",
    "    idf = inverse_document_frequency(tokenized_corpus, word, vocabulary)\n",
    "    tf_idf = tf * idf\n",
    "\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_frequency(listifiedLiedjes[200], 'blij')\n",
    "# inverse_document_frequency(listifiedLiedjes, 'blij', liedjesVocabulary)\n",
    "# tf_idf(listifiedLiedjes, listifiedLiedjes[200], 'coster', liedjesVocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_vocabulary(tokenized_corpus, vocabulary):\n",
    "    # output: dictionary with idf value per word in the tokenized corpus\n",
    "    idf_vocabulary = {}\n",
    "    for word in vocabulary:\n",
    "        idf = inverse_document_frequency(tokenized_corpus, word, vocabulary)\n",
    "        idf_vocabulary[word] = idf\n",
    "\n",
    "    return idf_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_voc = get_idf_vocabulary(listifiedLiedjes, liedjesVocabulary)\n",
    "sorted_idf_voc = dict(sorted(idf_voc.items(), key=lambda x: x[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coster -0.11720716463557396\n",
      "vreugde 0.14170683763976435\n",
      "feest 0.24375609199393478\n",
      "kunst 0.49625185532067184\n",
      "zingen 0.5005162541071294\n",
      "jaar 0.541961662282522\n",
      "eer 0.5736385189360921\n",
      "vrolijk 0.6087298387473621\n",
      "komt 0.6328273903264227\n",
      "geest 0.6352693939819745\n",
      "leven 0.7167393625767655\n",
      "gaan 0.74635121662341\n",
      "blij 0.7939126278223491\n",
      "hart 0.8498918955642503\n",
      "zien 0.9156432731270308\n",
      "laten 0.9188847670512017\n",
      "lied 0.9929927392049235\n",
      "dag 0.9964953697561256\n",
      "drukkunst 1.0106298806910303\n",
      "staan 1.0249670438374376\n",
      "heil 1.0505625910264014\n",
      "vieren 1.0542731704229371\n",
      "kopperfeest 1.065488241243077\n",
      "vriendschap 1.0960249651031588\n",
      "blijven 1.1235316108929922\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key, value in sorted_idf_voc.items():\n",
    "    if i < 25:\n",
    "        print(key, value)\n",
    "        i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
